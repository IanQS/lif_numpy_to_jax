{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2d138c-105a-4679-99d9-704c47a27570",
   "metadata": {},
   "source": [
    "# Jax scan\n",
    "\n",
    "## Goals:\n",
    "\n",
    "- explain why you'd want to use Jax's native loops\n",
    "\n",
    "- understanding `scan`\n",
    "\n",
    "- static arguments/ static argnames\n",
    "\n",
    "## Concepts:\n",
    "\n",
    "- reading haskell function signatures\n",
    "- partial functions\n",
    "- loopless-loops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec5912-6ec6-4fe7-81fd-1839854e8714",
   "metadata": {},
   "source": [
    "# Looping in Jax\n",
    "\n",
    "Is it possible to make jax `jit` more of the simulation for a larger speedup? Yes, but we need to address the \n",
    "\n",
    "we'd need to convert that pesky python `for-loop` into something that `jax` knows how to handle. Thankfully, `jax` provides:\n",
    "\n",
    "- [jax.lax.while_loop](https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.while_loop.html#jax.lax.while_loop)\n",
    "- [jax.lax.fori_loop](https://jax.readthedocs.io/en/latest/_autosummary/jax.lax.fori_loop.html)\n",
    "\n",
    "Note: we don't necessarily see a speedup in runtime (although that can happen). The primary advantage of using these jax functions is that the compilation time can be reduced. If you structure it well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad8c04-4574-47d1-a10f-1d4fe97b1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import TypeAlias\n",
    "import time\n",
    "\n",
    "from hyperparameters import (\n",
    "    _dt,\n",
    "    _t_max,\n",
    "    _tau_m,\n",
    "    _V_reset,\n",
    "    _V_thresh,\n",
    "    _R,\n",
    "    num_simulations\n",
    ")\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with open('weights.npy', 'rb') as f:\n",
    "    W = np.load(f)\n",
    "\n",
    "# Initial conditions\n",
    "n_neurons = len(W)# Number of neurons in the network\n",
    "_V = jnp.ones(n_neurons) * _V_reset  # Initial potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f14d01-6637-4daf-850f-7db1e38b7e56",
   "metadata": {},
   "source": [
    "# Type Definitions for Clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7932809-ea42-4e5d-9b59-838cd0ac2931",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor3D: TypeAlias = jnp.ndarray\n",
    "Mat: TypeAlias = jnp.ndarray\n",
    "Vec: TypeAlias = jnp.ndarray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b20fe3-eabd-4fc1-8361-681a1f0d9b42",
   "metadata": {},
   "source": [
    "# Fori_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9ed5b3-523d-4055-b743-246812c1611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@jax.jit\n",
    "def run_step(\n",
    "    v_prev,\n",
    "    v_thresh,\n",
    "    v_reset,\n",
    "\n",
    "    W,\n",
    "    tau_m,\n",
    "    dt,\n",
    "    membr_R,\n",
    "):\n",
    "    spiked = v_prev >= v_thresh\n",
    "    V = jnp.where(spiked, v_reset, v_prev)\n",
    "\n",
    "    # Update voltages\n",
    "    I_syn = W.dot(spiked)  # Synaptic current from spikes\n",
    "    dV = (dt / tau_m) * (-V + v_reset + membr_R * I_syn)\n",
    "    V = V + dV\n",
    "\n",
    "    # No self-inputs; neurons cannot spike themselves in this timestep\n",
    "    V = jnp.where(spiked, v_reset, V)\n",
    "    return V, spiked\n",
    "\n",
    "def run_simulation(W, V, tau_m, v_reset, v_thresh, membr_R, t_max, dt, num_steps):\n",
    "    def body_func(i, val):\n",
    "        V, spike_train = val\n",
    "        V, spike = run_step(V, v_thresh, v_reset, W, tau_m, dt, membr_R)\n",
    "        return (V, spike_train.at[i].set(spike))\n",
    "\n",
    "\n",
    "    spike_train = jnp.zeros((num_steps, len(W)), dtype=bool)\n",
    "    _, spike_train = jax.lax.fori_loop(0, num_steps, body_func, (V, spike_train))\n",
    "    return spike_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7f6f1-1fc8-48b1-a0b6-df0d86fed2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = []\n",
    "for i in range(num_simulations):\n",
    "    start = time.time()\n",
    "    spike_train = run_simulation(\n",
    "        jnp.asarray(W),\n",
    "        _V,\n",
    "        _tau_m, _V_reset, _V_thresh, _R,\n",
    "        _t_max, _dt, num_steps = int(_t_max / _dt)\n",
    "    )\n",
    "    end = time.time()\n",
    "    np.asarray(spike_train)\n",
    "    print(f\"Iteration {i} took: {end - start} seconds\")\n",
    "    time_arr.append(end - start)\n",
    "\n",
    "print(f\"Average Time: {np.mean(time_arr)}\")\n",
    "print(f\"S.Dev Time: {np.std(time_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d8a6d2-4e70-4aa8-87b3-b255bbe0ac03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2fd2191f-f7ae-4c72-b901-65e5344e2784",
   "metadata": {},
   "source": [
    "# Run the Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e369b-1270-4438-96ca-0dba39067fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "@partial(jax.jit, \n",
    "         static_argnames=['v_thresh', \"v_reset\", \"W\", \"tau_m\", \"dt\", \"membr_R\"],\n",
    "        )\n",
    "def run_step(v_prev, v_thresh, v_reset, W, tau_m, dt, membr_R):\n",
    "    spiked = v_prev >= v_thresh\n",
    "    V = jnp.where(spiked, v_reset, v_prev)\n",
    "\n",
    "    I_syn = W @ spiked.astype(jnp.float32)  # Synaptic current from spikes\n",
    "    reset_adjustment = v_reset + membr_R * I_syn\n",
    "    dV = (dt / tau_m) * (-V + reset_adjustment)\n",
    "    V = V + dV\n",
    "\n",
    "    V = jnp.where(spiked, v_reset, V)\n",
    "    return V, spiked\n",
    "\n",
    "\n",
    "def scan_step(carry, _):\n",
    "    (V, v_thresh, v_reset, W, tau_m, dt, membr_R) = carry\n",
    "    new_V, spike = run_step(V, v_thresh, v_reset, W, tau_m, dt, membr_R)\n",
    "    return (new_V, v_thresh, v_reset, W, tau_m, dt, membr_R), spike\n",
    "\n",
    "def run_simulation(W, V, tau_m, v_reset, v_thresh, membr_R, t_max, dt):\n",
    "    num_steps = int(t_max / dt)\n",
    "    # Run the scan over the number of time steps\n",
    "    final_V, accum_spikes = jax.lax.scan(\n",
    "        f=scan_step, \n",
    "        init=(V, v_thresh, v_reset, W, tau_m, dt, membr_R), \n",
    "        xs=jnp.arange(num_steps)\n",
    "    )\n",
    "    return accum_spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be8bcfe-aec0-4f4e-8312-099040e23d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = []\n",
    "for i in range(num_simulations):\n",
    "    start = time.time()\n",
    "    spike_train = run_simulation(\n",
    "        jnp.asarray(W),\n",
    "        _V,\n",
    "        _tau_m, _V_reset, _V_thresh, _R,\n",
    "        _t_max, _dt\n",
    "    )\n",
    "    end = time.time()\n",
    "    print(f\"Iteration {i} took: {end - start} seconds\")\n",
    "    time_arr.append(end - start)\n",
    "\n",
    "print(f\"Average Time: {np.mean(time_arr)}\")\n",
    "print(f\"S.Dev Time: {np.std(time_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f1030f-1f6d-4348-901c-3778af9eb95e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
