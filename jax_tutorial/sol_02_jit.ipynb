{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a2d138c-105a-4679-99d9-704c47a27570",
   "metadata": {},
   "source": [
    "# Jax jit\n",
    "\n",
    "## Lesson Goals:\n",
    "\n",
    "By the end of this lesson, you will know how to use the `jit`, how to accurately time computations using `jit`-ted functions, and how to identify where to `jit` things. In the process, we will quickly discuss functional programming and why functional programming is useful for speeding up computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597a69c0-35b4-4966-b6de-16757f3c078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypeAlias\n",
    "import time\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import jax\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56579c4-ee73-4e7b-b428-9505f7191d4c",
   "metadata": {},
   "source": [
    "# Functional Programming?\n",
    "\n",
    "Functional programming is many things, but for the purposes of this tutorial, it is a form of programming without side-effects. Python is not a functional programming language, but you may have heard of others such as `haskell`, `ocaml`, or `erlang`.\n",
    "\n",
    "The most common form of side-effects involves modifying some internal state. Consider the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a049b0b1-adc1-44ec-9f4d-7b22af832ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class ShoppingCart:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "\n",
    "    def add_item(self, item):\n",
    "        self.items.append(item)  # Side effect: modifying internal state\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"ShoppingCart({self.items})\"\n",
    "\n",
    "cart = ShoppingCart()\n",
    "cart.add_item(\"banana\")\n",
    "print(cart)\n",
    "cart.add_item(\"apple\")\n",
    "print(cart)\n",
    "print(\"*\" * 10)\n",
    "\n",
    "class FunctionalShoppingCart:\n",
    "    def __init__(self):\n",
    "        self.items = []\n",
    "\n",
    "    def add_item(self, item):\n",
    "        new_cart = FunctionalShoppingCart()\n",
    "        all_items = copy.deepcopy(self.items)\n",
    "        all_items.append(item)\n",
    "        new_cart.items = all_items\n",
    "        return new_cart\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"FunctionalShoppingCart({self.items})\"\n",
    "\n",
    "func_cart = FunctionalShoppingCart()\n",
    "func_cart.add_item(\"banana\")  # <- The banana was not added!\n",
    "print(func_cart)\n",
    "func_cart = func_cart.add_item(\"apple\")\n",
    "print(func_cart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f26b1-de6a-499a-a617-8704087de88c",
   "metadata": {},
   "source": [
    "## Functional Programming:\n",
    "\n",
    "Okay, but how is this relevant? Well, functional programming allows for:\n",
    "\n",
    "- predictable behavior: compilers can more easily optimize your code\n",
    "- immutability: the data cannot be modified, so all threads/ processes just grab a copy of the original data and process it async."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe45c7-c7d5-4e7c-8e7c-c1c9aaa83669",
   "metadata": {},
   "source": [
    "# Jax's JIT: Supercharged functions\n",
    "\n",
    "A `jit` is a just-in-time compilation of your code. `Python` is famously slow because, among other things, the code is interpreted i.e. at run-time, the interpreter has to decide what to do. Languages like `C++` are `Rust` are compiled so at run-time, the code is just... run.\n",
    "\n",
    "So, by compiling out Jax code via the `jit`, we can accelerate our programs. Assuming the numerical computation is the bottleneck, as is often the case in ML tasks, this means that we have sped up the slowest part of our program.\n",
    "\n",
    "## Where does functional programming come in? \n",
    "\n",
    "FP makes it easier for the `jit` compiler to speed up the code. It can do things like:\n",
    "\n",
    "- function inlining: the function call is replaced by the function itself\n",
    "\n",
    "- loop fusion/elimination/unrolling: by removing dependencies between calls, jax can \n",
    "\n",
    "- memoization: jax can cache results for particular inputs and return those if it sees those particular inputs again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5e698-198f-4028-8723-c9ea6ce3cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_arr = np.random.rand(1000, 1000)\n",
    "\n",
    "def func_np(m):\n",
    "    mask = m > 0.5\n",
    "    m = np.where(mask, m**2, np.sqrt(m))\n",
    "    return m @ m\n",
    "\n",
    "print(\"Numpy version\")\n",
    "%timeit func_np(input_arr)\n",
    "\n",
    "input_arr_j = jnp.asarray(input_arr)\n",
    "\n",
    "def func_jax(m):\n",
    "    mask = m > 0.5\n",
    "    mod_m = jnp.where(mask, m**2, jnp.sqrt(m))\n",
    "    return mod_m @ mod_m\n",
    "\n",
    "print(\"Jax Non-Jit version\")\n",
    "%timeit func_jax(input_arr_j)\n",
    "\n",
    "jitted_func = jax.jit(func_jax)\n",
    "\n",
    "print(\"Jax Jitted version\")\n",
    "%timeit jitted_func(input_arr_j).block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a26b4f-a812-4739-979f-a2fab006200e",
   "metadata": {},
   "source": [
    "## Quick Aside: Benchmarking in Jax\n",
    "\n",
    "The astute would have noticed the `.block_until_ready()` function call. What gives? Well, jax returns a future to prevent blocking the main python thread. So, to get accurate timings we had to use the `.block_until_ready()`. To ensure that you get accurate timings when benchmarking you can:\n",
    "\n",
    "- use `.block_until_ready()`\n",
    "- convert the `jnp.array` into `np.array` to wait for the future\n",
    "- print the `jnp.array`\n",
    "\n",
    "For more information check out: [Jax Async Dispatch](https://jax.readthedocs.io/en/latest/async_dispatch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbad8c04-4574-47d1-a10f-1d4fe97b1cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from hyperparameters import (\n",
    "    _dt,\n",
    "    _t_max,\n",
    "    _tau_m,\n",
    "    _V_reset,\n",
    "    _V_thresh,\n",
    "    _R,\n",
    "    num_simulations\n",
    ")\n",
    "\n",
    "\n",
    "with open('weights.npy', 'rb') as f:\n",
    "    W = np.load(f)\n",
    "\n",
    "# Initial conditions\n",
    "n_neurons = len(W)# Number of neurons in the network\n",
    "_V = jnp.ones(n_neurons) * _V_reset  # Initial potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f14d01-6637-4daf-850f-7db1e38b7e56",
   "metadata": {},
   "source": [
    "# Type Definitions for Clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7932809-ea42-4e5d-9b59-838cd0ac2931",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor3D: TypeAlias = jnp.ndarray\n",
    "Mat: TypeAlias = jnp.ndarray\n",
    "Vec: TypeAlias = jnp.ndarray "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd2191f-f7ae-4c72-b901-65e5344e2784",
   "metadata": {},
   "source": [
    "# Run the Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7a3eb-965a-4ee5-973d-a16ef6c1fd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(\n",
    "    W: Mat,\n",
    "    V: Vec,\n",
    "\n",
    "    # Neuron Parameters\n",
    "    tau_m: float,\n",
    "    v_reset: float,\n",
    "    v_thresh: float,\n",
    "    membr_R: float,\n",
    "\n",
    "    # How long do we run for? \n",
    "    t_max: float,\n",
    "    dt: float, \n",
    "\n",
    "):\n",
    "    # Simulation\n",
    "\n",
    "    spike_train = []\n",
    "    for i, t in enumerate(np.arange(0, t_max, dt)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        V, spike = run_step(V, v_thresh, v_reset, W, tau_m, dt, membr_R)\n",
    "        spike_train.append(spike)\n",
    "\n",
    "    return spike_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f31064-384c-4dc6-bf20-2855065262f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def run_step(\n",
    "    v_prev,\n",
    "    v_thresh,\n",
    "    v_reset,\n",
    "\n",
    "    W,\n",
    "    tau_m,\n",
    "    dt,\n",
    "    membr_R,\n",
    "):\n",
    "    spiked = v_prev >= v_thresh\n",
    "    V = jnp.where(spiked, v_reset, v_prev)\n",
    "\n",
    "    # Update voltages\n",
    "    I_syn = W.dot(spiked)  # Synaptic current from spikes\n",
    "    dV = (dt / tau_m) * (-V + v_reset + membr_R * I_syn)\n",
    "    V = V + dV\n",
    "\n",
    "    # No self-inputs; neurons cannot spike themselves in this timestep\n",
    "    V = jnp.where(spiked, v_reset, V)\n",
    "    return V, spiked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b4fcc6-6cab-4f63-9672-9b4ea02d13de",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = []\n",
    "for i in range(num_simulations):\n",
    "    start = time.time()\n",
    "    spike_train = run_simulation(\n",
    "        W,\n",
    "        _V,\n",
    "        _tau_m, _V_reset, _V_thresh, _R,\n",
    "        _t_max, _dt\n",
    "    )\n",
    "    np.asarray(spike_train)\n",
    "    end = time.time()\n",
    "    print(f\"Iteration {i} took: {end - start} seconds\")\n",
    "    time_arr.append(end - start)\n",
    "    if i == 1:\n",
    "        print(\"Breaking out - point proven\")\n",
    "        break\n",
    "\n",
    "print(f\"Average Time: {np.mean(time_arr)}\")\n",
    "print(f\"S.Dev Time: {np.std(time_arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da305ad7-8d91-4223-a90d-c1353ab4e9e3",
   "metadata": {},
   "source": [
    "# What gives? \n",
    "\n",
    "`jax.jit` doesn't always play nicely with numpy! There are times where calling `jnp.asarray` is necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506fc2de-aa78-41ca-81eb-3124c115c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_arr = []\n",
    "for i in range(num_simulations):\n",
    "    start = time.time()\n",
    "    spike_train = run_simulation(\n",
    "        jnp.asarray(W),\n",
    "        _V,\n",
    "        _tau_m, _V_reset, _V_thresh, _R,\n",
    "        _t_max, _dt\n",
    "    )\n",
    "    np.asarray(spike_train)\n",
    "    end = time.time()\n",
    "    print(f\"Iteration {i} took: {end - start} seconds\")\n",
    "    time_arr.append(end - start)\n",
    "\n",
    "print(f\"Average Time: {np.mean(time_arr)}\")\n",
    "print(f\"S.Dev Time: {np.std(time_arr)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91d6be-440a-4dba-88f3-3dac786a27da",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "\n",
    "1) Read through [extras_when_not_to_jit.ipynb](./extras_when_not_to_jit.ipynb)\n",
    "\n",
    "2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
