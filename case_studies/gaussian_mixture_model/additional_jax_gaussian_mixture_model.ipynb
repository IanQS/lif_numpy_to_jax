{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f5eb3a90919eb4a",
   "metadata": {},
   "source": [
    "# Additional Gaussian_Mixture_Model\n",
    "\n",
    "## Motivation\n",
    "\n",
    "In the first notebook [core_jax_GMM](./core_jax_gaussian_mixture_model.ipynb), we initialized our initial clusters by \"cheating\" in that we used the unknowable true centers and adding noise. This worked\n",
    "great as a teaching and sanity-checking tool, but in reality we can not know this. So, we initialize in many random locations and with a few cluster centers.\n",
    "\n",
    "For this notebook, we take the concepts and code from our first notebook [core_jax_GMM](./core_jax_gaussian_mixture_model.ipynb) and expand on them. Some new concepts used:\n",
    "\n",
    "- `RNG` for reproducible initializations of the mus and\n",
    "- `PMAP` for parallelization of the GMM across the initializations\n",
    "\n",
    "Before each newly introduced concept we briefly discuss the arguments and why the code is laid out the way it is :)"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:53:03.268345Z",
     "start_time": "2024-06-21T20:53:03.266607Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import OS and specify the number of devices to force simulate BEFORE importing Jax\n",
    "#   comment me out and run the next two lines to see what happens if we do not do this correctly\n",
    "import os\n",
    "os.environ['XLA_FLAGS'] = \"--xla_force_host_platform_device_count=8\"\n"
   ],
   "id": "1d6e64dfeaf9d061",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "7a93ff9ca2164e2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:53:03.734808Z",
     "start_time": "2024-06-21T20:53:03.286909Z"
    }
   },
   "source": [
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import numpy as np\n",
    "np.random.seed(123)\n",
    "\n",
    "from additional_gmm import unknown_centers, make_ds, EM_GMM"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:53:03.747635Z",
     "start_time": "2024-06-21T20:53:03.735414Z"
    }
   },
   "cell_type": "code",
   "source": "jax.devices()",
   "id": "e04405ed47ee9fe4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[CpuDevice(id=0),\n",
       " CpuDevice(id=1),\n",
       " CpuDevice(id=2),\n",
       " CpuDevice(id=3),\n",
       " CpuDevice(id=4),\n",
       " CpuDevice(id=5),\n",
       " CpuDevice(id=6),\n",
       " CpuDevice(id=7)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Randomness\n",
    "\n",
    "Jax's `random.key` and `random.split` returns a vector or array of shape (N, `2). You don't actually access the underlying two values, but they are instead passed as a single value to Jax"
   ],
   "id": "f04147ab7bfabb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:53:05.018402Z",
     "start_time": "2024-06-21T20:53:04.927810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from jax import random\n",
    "\n",
    "def simple_rng_example(seed=42):\n",
    "    init_key = random.key(seed)\n",
    "    keys_and_subkeys = random.split(init_key, num=len(jax.devices()))\n",
    "\n",
    "    print(\"Our resulting array from the split\")\n",
    "    print(keys_and_subkeys)\n",
    "    \n",
    "    try:\n",
    "        keys_and_subkeys[0][0]\n",
    "    except Exception as e:\n",
    "        print(\"\\n\")\n",
    "        print(\"The error when trying to access individual elements of each key\")\n",
    "        print(e)\n",
    "simple_rng_example(42)"
   ],
   "id": "371eac836b180fad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our resulting array from the split\n",
      "Array((8,), dtype=key<fry>) overlaying:\n",
      "[[1016697191 1792542510]\n",
      " [  21752309 3647990511]\n",
      " [ 344551668 3939928494]\n",
      " [ 861363423  169498067]\n",
      " [2390192106  167227791]\n",
      " [ 201508585 2676631123]\n",
      " [3104550939 3018605412]\n",
      " [ 775411565  603659288]]\n",
      "\n",
      "\n",
      "The error when trying to access individual elements of each key\n",
      "Too many indices for array: 1 non-None/Ellipsis indices for dim 0.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:53:05.421973Z",
     "start_time": "2024-06-21T20:53:05.419890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seed = 42\n",
    "init_key = random.key(seed)\n",
    "keys_and_subkeys = random.split(init_key, num=len(jax.devices()))"
   ],
   "id": "385b75b32067a668",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Create the function to be `pmap`-ed\n",
    "\n",
    "We create a wrapping function that encompasses the logic of taking in a random seed for initializing the guessed centers"
   ],
   "id": "25fc00d34daabbe4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:53:06.429727Z",
     "start_time": "2024-06-21T20:53:06.427342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "def wrapped_gmm(ndims, K):\n",
    "    def run_gmm(rk, X):\n",
    "        main_key, subkey = random.split(rk)\n",
    "        jax.debug.print(\"Dimensions: {ndims}\", ndims=ndims)\n",
    "        jax.debug.print(\"Clusters: {K}\", K=K)\n",
    "        # We can use the `main_key` for further random operations. The subkey should NOT be reused\n",
    "        mus = jax.random.normal(subkey, shape=(K, ndims))\n",
    "\n",
    "        sigmas = jnp.asarray([jnp.cov(X.T) for _ in range(K)])\n",
    "        cls_probs = jnp.asarray([1 / K for _ in range(K)]).T\n",
    "        cls_probs = jnp.expand_dims(cls_probs, axis=-1)\n",
    "        return EM_GMM(\n",
    "            X,\n",
    "            mus=mus,\n",
    "            sigmas=sigmas,\n",
    "            cls_probs=cls_probs,\n",
    "            guess_num_classes=K,\n",
    "            verbose=False\n",
    "        )\n",
    "    return run_gmm"
   ],
   "id": "c68dc22605eeef21",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Setting up the `pmap`\n",
    "\n",
    "`pmap` is very similar to `vmap`, but instead of applying a function across a mapped axis, it copies the function and executes it on each device.\n",
    "\n",
    "Here we are mapping the random keys over the devices, so we specify that we map it over the 0th axis\n",
    "\n"
   ],
   "id": "3740f9d7f5fdfa4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Run the parallel training\n",
    "\n",
    "For each cluster number, we run "
   ],
   "id": "fec911f165461069"
  },
  {
   "cell_type": "code",
   "id": "d148bd2472eca73e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T20:53:10.009936Z",
     "start_time": "2024-06-21T20:53:08.815191Z"
    }
   },
   "source": [
    "(X, y), _ = make_ds(unknown_centers)\n",
    "\n",
    "N, M = X.shape\n",
    "\n",
    "all_results = []\n",
    "for num_clusters in range(1, 5):\n",
    "\n",
    "    run_gmm = wrapped_gmm(M, num_clusters)\n",
    "    parallel_gmm = jax.pmap(\n",
    "        run_gmm,\n",
    "        in_axes=(0, None)\n",
    "    )\n",
    "    \n",
    "    res = parallel_gmm(keys_and_subkeys, X)\n",
    "    all_results.append(res)"
   ],
   "outputs": [
    {
     "ename": "TracerBoolConversionError",
     "evalue": "Attempted boolean conversion of traced array with shape bool[1]..\nThe error occurred while tracing the function run_gmm at /tmp/ipykernel_602810/65220928.py:4 for pmap. This concrete value was not available in Python because it depends on the values of the arguments rk and X.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTracerBoolConversionError\u001B[0m                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 14\u001B[0m\n\u001B[1;32m      8\u001B[0m run_gmm \u001B[38;5;241m=\u001B[39m wrapped_gmm(M, num_clusters)\n\u001B[1;32m      9\u001B[0m parallel_gmm \u001B[38;5;241m=\u001B[39m jax\u001B[38;5;241m.\u001B[39mpmap(\n\u001B[1;32m     10\u001B[0m     run_gmm,\n\u001B[1;32m     11\u001B[0m     in_axes\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     12\u001B[0m )\n\u001B[0;32m---> 14\u001B[0m res \u001B[38;5;241m=\u001B[39m parallel_gmm(keys_and_subkeys, X)\n\u001B[1;32m     15\u001B[0m all_results\u001B[38;5;241m.\u001B[39mappend(res)\n",
      "    \u001B[0;31m[... skipping hidden 12 frame]\u001B[0m\n",
      "Cell \u001B[0;32mIn[6], line 14\u001B[0m, in \u001B[0;36mwrapped_gmm.<locals>.run_gmm\u001B[0;34m(rk, X)\u001B[0m\n\u001B[1;32m     12\u001B[0m cls_probs \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39masarray([\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m K \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(K)])\u001B[38;5;241m.\u001B[39mT\n\u001B[1;32m     13\u001B[0m cls_probs \u001B[38;5;241m=\u001B[39m jnp\u001B[38;5;241m.\u001B[39mexpand_dims(cls_probs, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m EM_GMM(\n\u001B[1;32m     15\u001B[0m     X,\n\u001B[1;32m     16\u001B[0m     mus\u001B[38;5;241m=\u001B[39mmus,\n\u001B[1;32m     17\u001B[0m     sigmas\u001B[38;5;241m=\u001B[39msigmas,\n\u001B[1;32m     18\u001B[0m     cls_probs\u001B[38;5;241m=\u001B[39mcls_probs,\n\u001B[1;32m     19\u001B[0m     guess_num_classes\u001B[38;5;241m=\u001B[39mK,\n\u001B[1;32m     20\u001B[0m     verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m     21\u001B[0m )\n",
      "File \u001B[0;32m~/research/lif_numpy_to_jax/case_studies/gaussian_mixture_model/additional_gmm.py:158\u001B[0m, in \u001B[0;36mEM_GMM\u001B[0;34m(data, guess_num_classes, mus, sigmas, cls_probs, verbose)\u001B[0m\n\u001B[1;32m    155\u001B[0m \u001B[38;5;66;03m# Recalculate the log-likelihood\u001B[39;00m\n\u001B[1;32m    156\u001B[0m ll_curr \u001B[38;5;241m=\u001B[39m log_likelihood(data, mus, sigmas, cls_probs, guess_num_classes)\n\u001B[0;32m--> 158\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m jnp\u001B[38;5;241m.\u001B[39mabs(ll_container[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m-\u001B[39m ll_curr) \u001B[38;5;241m<\u001B[39m TOL:\n\u001B[1;32m    159\u001B[0m     jax\u001B[38;5;241m.\u001B[39mdebug\u001B[38;5;241m.\u001B[39mprint(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConverged to within \u001B[39m\u001B[38;5;132;01m{TOL}\u001B[39;00m\u001B[38;5;124m after: \u001B[39m\u001B[38;5;132;01m{counter}\u001B[39;00m\u001B[38;5;124m iterations\u001B[39m\u001B[38;5;124m\"\u001B[39m, TOL\u001B[38;5;241m=\u001B[39mTOL, counter\u001B[38;5;241m=\u001B[39mcounter)\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping hidden 1 frame]\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/envs/numpy_to_jax/lib/python3.12/site-packages/jax/_src/core.py:1492\u001B[0m, in \u001B[0;36mconcretization_function_error.<locals>.error\u001B[0;34m(self, arg)\u001B[0m\n\u001B[1;32m   1491\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21merror\u001B[39m(\u001B[38;5;28mself\u001B[39m, arg):\n\u001B[0;32m-> 1492\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m TracerBoolConversionError(arg)\n",
      "\u001B[0;31mTracerBoolConversionError\u001B[0m: Attempted boolean conversion of traced array with shape bool[1]..\nThe error occurred while tracing the function run_gmm at /tmp/ipykernel_602810/65220928.py:4 for pmap. This concrete value was not available in Python because it depends on the values of the arguments rk and X.\nSee https://jax.readthedocs.io/en/latest/errors.html#jax.errors.TracerBoolConversionError"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "bc9e90ab22ecd2da",
   "metadata": {},
   "source": [
    "# Result Investigation"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b828210f2680835",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-21T19:41:51.121300Z",
     "start_time": "2024-06-21T19:41:51.121236Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plot the Log-likelihood",
   "id": "817f6b4b0716139"
  },
  {
   "cell_type": "code",
   "id": "b3c282a6ef7d6948",
   "metadata": {},
   "source": [
    "plt.plot(lls)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Log-likelihood of points\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Show the Points",
   "id": "823f8adff3d7d5ce"
  },
  {
   "cell_type": "code",
   "id": "cb5a972edcead218",
   "metadata": {},
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "def confidence_ellipse(mu, sigma, ax, n_std=3.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Modified based on function from: https://matplotlib.org/stable/gallery/statistics/confidence_ellipse.html\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The Axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    pearson = sigma[0, 1]/np.sqrt(sigma[0, 0] * sigma[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensional dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the standard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(sigma[0, 0]) * n_std\n",
    "    # calculating the standard deviation of y ...\n",
    "    scale_y = np.sqrt(sigma[1, 1]) * n_std\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mu[0], mu[1])\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd816d30afbdaa83",
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "colors = [\"r\", \"g\", \"b\", \"y\"]\n",
    "\n",
    "for i, c in enumerate(colors):\n",
    "    \n",
    "    # Plot the centers\n",
    "    plt.scatter(unknown_centers[i, 0], unknown_centers[i, 1], c=c, marker=\"o\", label=f\"Cluster: {i} True Center\")\n",
    "    plt.scatter(mus[i, 0], mus[i, 1], c=c, marker=\"^\", label=f\"Cluster: {i} Inferred Center\")\n",
    "    \n",
    "    # Plot the standard deviations\n",
    "    mask = y == i\n",
    "    masked_points = X[mask]\n",
    "    mu_x = np.mean(masked_points, axis=0)\n",
    "    sigma = np.cov(masked_points[:, 0], masked_points[:, 1])\n",
    "    confidence_ellipse(mu_x, sigma,  ax=axs, n_std=1, edgecolor=c, linestyle=\"-\")\n",
    "    confidence_ellipse(mu_x, sigma, ax=axs, n_std=2, edgecolor=c, linestyle=\"-\")\n",
    "    confidence_ellipse(mu_x, sigma, ax=axs, n_std=3, edgecolor=c, linestyle=\"-\")\n",
    "\n",
    "\n",
    "    confidence_ellipse(mus[i], sigmas[i],  ax=axs, n_std=1, edgecolor=c, linestyle=\"--\")\n",
    "    confidence_ellipse(mus[i], sigmas[i], ax=axs, n_std=2, edgecolor=c, linestyle=\"--\")\n",
    "    confidence_ellipse(mus[i], sigmas[i], ax=axs, n_std=3, edgecolor=c, linestyle=\"--\")\n",
    "plt.legend(loc=\"best\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Followup\n",
    "\n",
    "For more advanced concepts, please check out []()"
   ],
   "id": "6ca8d95b632922fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
